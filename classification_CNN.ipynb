{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "from keras.models import Model # basic class for specifying and training a neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Convolution2D, MaxPooling2D, Dropout\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "from keras.regularizers import l2 # L2-regularisation\n",
    "from keras.layers.normalization import BatchNormalization # batch normalisation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/12\n",
      "6300/6300 [==============================] - 0s 41us/step - loss: 2.2189 - acc: 0.3456 - val_loss: 2.1039 - val_acc: 0.5114\n",
      "Epoch 2/12\n",
      "6300/6300 [==============================] - 0s 14us/step - loss: 1.8959 - acc: 0.6919 - val_loss: 1.6916 - val_acc: 0.6986\n",
      "Epoch 3/12\n",
      "6300/6300 [==============================] - 0s 14us/step - loss: 1.4097 - acc: 0.7930 - val_loss: 1.2373 - val_acc: 0.7757\n",
      "Epoch 4/12\n",
      "6300/6300 [==============================] - 0s 14us/step - loss: 0.9929 - acc: 0.8478 - val_loss: 0.9114 - val_acc: 0.8143\n",
      "Epoch 5/12\n",
      "6300/6300 [==============================] - 0s 14us/step - loss: 0.7231 - acc: 0.8705 - val_loss: 0.7104 - val_acc: 0.8414\n",
      "Epoch 6/12\n",
      "6300/6300 [==============================] - 0s 14us/step - loss: 0.5636 - acc: 0.8887 - val_loss: 0.5891 - val_acc: 0.8600\n",
      "Epoch 7/12\n",
      "6300/6300 [==============================] - 0s 14us/step - loss: 0.4662 - acc: 0.9029 - val_loss: 0.5104 - val_acc: 0.8743\n",
      "Epoch 8/12\n",
      "6300/6300 [==============================] - 0s 14us/step - loss: 0.4044 - acc: 0.9097 - val_loss: 0.4576 - val_acc: 0.8886\n",
      "Epoch 9/12\n",
      "6300/6300 [==============================] - 0s 14us/step - loss: 0.3614 - acc: 0.9157 - val_loss: 0.4217 - val_acc: 0.9000\n",
      "Epoch 10/12\n",
      "6300/6300 [==============================] - 0s 14us/step - loss: 0.3297 - acc: 0.9219 - val_loss: 0.3935 - val_acc: 0.9000\n",
      "Epoch 11/12\n",
      "6300/6300 [==============================] - 0s 16us/step - loss: 0.3054 - acc: 0.9238 - val_loss: 0.3718 - val_acc: 0.9043\n",
      "Epoch 12/12\n",
      "6300/6300 [==============================] - 0s 15us/step - loss: 0.2877 - acc: 0.9287 - val_loss: 0.3559 - val_acc: 0.9100\n",
      "4000/4000 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.295832428753376, 0.92425]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model\n",
    "num_classes = 10\n",
    "# Each image is 8 by 8 pixels and is represented as a vector of dimension 64 \n",
    "# by listing all the pixel values in raster scan order. The images are grayscale \n",
    "# and the pixel values are between 0 and 1.\n",
    "train_data, train_labels, test_data, test_labels = data.load_all_data('data')\n",
    "train_labels = np_utils.to_categorical(train_labels, num_classes) # One-hot encode the labels\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes) # One-hot encode the labels\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=64, kernel_initializer='normal', activation='relu')) # rectifier activation function\n",
    "model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels, epochs=12, batch_size=200, verbose=1, validation_split=0.1)\n",
    "model.evaluate(test_data, test_labels, verbose=1) # test accuracy 0.924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBxIjcCAxAgcS+y9yE8RF1YxwcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120311978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBA4kRuBAYgQOJEbgQGIEDiT2X5NIs0il/b7TAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1192b7e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xdat = train_data.reshape(train_data.shape[0], height, width)\n",
    "plt.imshow(Xdat[4], cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "plt.imshow(Xdat[5], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, depth = 8, 8, 1\n",
    "train_data = train_data.reshape(train_data.shape[0], height, width, depth)\n",
    "test_data = test_data.reshape(test_data.shape[0], height, width, depth)\n",
    "\n",
    "kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth = 32 # use 32 kernels in both convolutional layers\n",
    "drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "hidden_size = 128 # there will be 128 neurons in both hidden layers\n",
    "l2_lambda = 0.0001 # use 0.0001 as a L2-regularisation factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 8, 8, 1)\n",
      "(7000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(height, width, depth)) # N.B. TensorFlow back-end expects channel dimension last\n",
    "conv_1 = Convolution2D(conv_depth, (kernel_size, kernel_size), padding='same', kernel_initializer='he_uniform', \n",
    "                       kernel_regularizer=l2(l2_lambda), activation='relu')(inp)\n",
    "conv_2 = Convolution2D(conv_depth, (kernel_size, kernel_size), padding='same', kernel_initializer='he_uniform', \n",
    "                       kernel_regularizer=l2(l2_lambda), activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2) # pooling layer\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1) # a regularization layer using dropout\n",
    "flat = Flatten()(drop_1) # converts the 2D matrix data to a vector\n",
    "hidden = Dense(hidden_size, activation='relu')(flat) # Hidden ReLU layer\n",
    "drop = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop) # Output softmax layer\n",
    "model = Model(inputs=inp, outputs=out) # To define a model, just specify its input and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/12\n",
      "6300/6300 [==============================] - 2s 365us/step - loss: 0.0493 - acc: 0.9911 - val_loss: 0.0743 - val_acc: 0.9857\n",
      "Epoch 2/12\n",
      "6300/6300 [==============================] - 1s 232us/step - loss: 0.0563 - acc: 0.9863 - val_loss: 0.0687 - val_acc: 0.9871\n",
      "Epoch 3/12\n",
      "6300/6300 [==============================] - 1s 233us/step - loss: 0.0479 - acc: 0.9902 - val_loss: 0.0679 - val_acc: 0.9857\n",
      "Epoch 4/12\n",
      "6300/6300 [==============================] - 1s 234us/step - loss: 0.0457 - acc: 0.9908 - val_loss: 0.0714 - val_acc: 0.9871\n",
      "Epoch 5/12\n",
      "6300/6300 [==============================] - 2s 243us/step - loss: 0.0457 - acc: 0.9894 - val_loss: 0.0725 - val_acc: 0.9857\n",
      "Epoch 6/12\n",
      "6300/6300 [==============================] - 1s 234us/step - loss: 0.0441 - acc: 0.9905 - val_loss: 0.0730 - val_acc: 0.9871\n",
      "Epoch 7/12\n",
      "6300/6300 [==============================] - 1s 236us/step - loss: 0.0497 - acc: 0.9897 - val_loss: 0.0737 - val_acc: 0.9857\n",
      "Epoch 8/12\n",
      "6300/6300 [==============================] - 2s 247us/step - loss: 0.0453 - acc: 0.9914 - val_loss: 0.0717 - val_acc: 0.9886\n",
      "Epoch 9/12\n",
      "6300/6300 [==============================] - 1s 234us/step - loss: 0.0446 - acc: 0.9911 - val_loss: 0.0761 - val_acc: 0.9857\n",
      "Epoch 10/12\n",
      "6300/6300 [==============================] - 1s 237us/step - loss: 0.0475 - acc: 0.9900 - val_loss: 0.0716 - val_acc: 0.9871\n",
      "Epoch 11/12\n",
      "6300/6300 [==============================] - 1s 235us/step - loss: 0.0412 - acc: 0.9922 - val_loss: 0.0668 - val_acc: 0.9857\n",
      "Epoch 12/12\n",
      "6300/6300 [==============================] - 2s 248us/step - loss: 0.0395 - acc: 0.9922 - val_loss: 0.0678 - val_acc: 0.9886\n",
      "4000/4000 [==============================] - 0s 107us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.053265751853585244, 0.98925]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          batch_size=300, epochs=12,\n",
    "          verbose=1, validation_split=0.1) # 10% data for validation\n",
    "model.evaluate(test_data, test_labels, verbose=1) # test loss 0.05, test accuracy 0.98925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}